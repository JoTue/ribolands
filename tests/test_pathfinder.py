#!/usr/bin/env python3

import RNA
import unittest
from itertools import combinations

from ribolands.utils import make_pair_table
from ribolands.pathfinder import (findpath_split,
                                  common_basepairs,
                                  common_exterior_bases, 
                                  split_struct,
                                  merge_struct,
                                  local_flooding,
                                  path_flooding, 
                                  edge_flooding,
                                  init_findpath_max,
                                  findpath_max,
                                  get_guide_graph,
                                  guiding_edge_search,
                                  guiding_node_search,
                                  forbid_all_basepairs,
                                  get_basepairs,
                                  nx_cycle_basis,
                                  mfe_intersect,
                                  neighborhood_flooding,
                                  neighborhood_coarse_graining)

from ribolands.parser import parse_barriers

SKIP = False

@unittest.skipIf(SKIP, "skipping tests")
class MaxPathTests(unittest.TestCase):
    #def test_cache(self):
    #    search_width_multiplier = 4
    #    mp = True
    #     
    #    sequence = 'UCCGACAUUAAGACACACCAGGGUCUCGUAUCCCUAGGGUAAGGUACGCGCGGACCGGCCAAUCGGGUAUUGCUGCAAACUAUGGCAAUAGUGCAUAGGUUCAGACGAAGUACGGGUGGAUAUUUGUAGCCAGUAUGCUGGGUCUCCGGG'
    #    fp = maxpath.findpath_class(sequence, mp)
    #    
    #    s1       = '((((..........((.((((((........)))).))))..........))))((((...(((.(((((.((((((((((((.(((....)))))))(((((..((.....))..))))).))))))))....))))).)))..)))).'
    #    s2       = '((((..........((.((((((........)))).))))..........))))((((....((((((((((((((((((((((((....)).)))))(((((..((.....))..))))).)))))))).))))).))))....)))).'
    #    result = fp.init(s1, s2, search_width_multiplier)
    #    print(result)
    #    
    #    s1       = '((((..........((.((((((........)))).))))..........))))((((...(((.(((((.((((((((((((.(((....)))))))(((((..((.....))..))))).))))))))....))))).)))..)))).'
    #    s2       = '((((....((....((.((((((........)))).))))....))....))))((((....((((((((((((((((((((((((....)).)))))(((((..((.....))..))))).))))))).)))))).))))....)))).'
    #    result = fp.init(s1, s2, search_width_multiplier)
    #    print(result)


    def test_findpath_split_02(self):
        seq = "UGGGAAUAGUCUCUUCCGAGUCUCGCGGGCGACGGGCGAUCUUCGAAAGUGGAAUCCG"
        ss1 = "..((....(((........(((.....)))....)))..(((........)))..))." 
        ss2 = ".((((....))))..(((.(.((...)).)..)))......(((.......)))...."
        #print(f'\n{seq}\n{ss1}\n{ss2}')
        path, barrier = findpath_split(seq, ss1, ss2, RNA.md(), th = 1)
        assert barrier == 200 # may change with a new findpath version?

    def test_mfe_intersect(self):
        seq = "UGGGAAUAGUCUCUUCCGAGUCUCGCGGGCGACGGGCGAUCUUCGAAAGUGGAAUCCG"
        ss1 = "..((....(((........(((.....)))....)))..(((........)))..))." 
        ss2 = ".((((....))))..(((.(.((...)).)..)))......(((.......)))...."
        bps = get_basepairs([ss1, ss2])
        mss, mfe = mfe_intersect(seq, RNA.md(), bps)
        assert mss != ss1
        assert mss != ss2

    def test_mfe_intersect(self):
        seq = "UGGGAAUAGUCUCUUCCGAGUCUCGCGGGCGACGGGCGAUCUUCGAAAGUGGAAUCCG"
        ss1 = "..((....(((........(((.....)))....)))..(((........)))..))." 
        ss2 = ".((((....))))..(((.((((...))))..)))....(((........)))....."
        bps = get_basepairs([ss1, ss2])
        mss, mfe = mfe_intersect(seq, RNA.md(), bps)
        assert mss == ss2
 
    def test_mfe_intersect(self):
        seq = 'UCCGACAUUAAGACACACCAGGGUCUCGUAUCCCUAGGGUAAGGUACGCGCGGACCGGCCAAUCGGGUAUUGCUGCAAACUAUGGCAAUAGUGCAUAGGUUCAGACGAAGUACGGGUGGAUAUUUGUAGCCAGUAUGCUGGGUCUCCGGG'
        ss1 = '((((..........((.((((((........)))).))))..........))))((((...(((.(((((.((((((((((((.(((....)))))))(((((..((.....))..))))).))))))))....))))).)))..)))).'
        ss2 = '((((..........((.((((((........)))).))))..........))))((((....((((((((((((((((((((((((....)).)))))(((((..((.....))..))))).)))))))).))))).))))....)))).'
        ss3 = '((((..........((.((((((........)))).))))..........))))((((....((((((((((((((((((((((.((....)))))))(((((..((.....))..))))).)))))))).))))).))))....)))).'
        bps = get_basepairs([ss1, ss2, ss3])
        mss, mfe = mfe_intersect(seq, RNA.md(), bps)
        assert mss == ss3

@unittest.skipIf(SKIP, "skipping tests")
class FindpathTests(unittest.TestCase):
    def test_split_merge_01(self):
        seq = 'GCCUUAAGCCUACUUAGAUGGAAGUGACGUACGGGUAUU'
        ss1 = '(......((((((((......)))).......))))..)'
        ss2 = '((((.......((((......)))).......)))...)'
        pt1 = make_pair_table(ss1, base = 0)
        pt2 = make_pair_table(ss2, base = 0)

        ceb = []
        assert list(common_exterior_bases(pt1, pt2)) == ceb
        for x in common_exterior_bases(pt1, pt2):
            assert seq == merge_struct(*split_struct(seq, x, None), x, None)
            assert ss1 == merge_struct(*split_struct(ss1, x, None), x, None)
            assert ss2 == merge_struct(*split_struct(ss2, x, None), x, None)

        cbp = [(0, 38), (11, 24), (12, 23), (13, 22), (14, 21)]
        assert list(common_basepairs(pt1, pt2)) == cbp
        for x in common_basepairs(pt1, pt2):
            assert seq == merge_struct(*split_struct(seq, *x), *x)
            assert ss1 == merge_struct(*split_struct(ss1, *x), *x)
            assert ss2 == merge_struct(*split_struct(ss2, *x), *x)

    def test_split_merge_02(self):
        seq = 'AAAGCCGCCUUAAACGGGUAUUGGUACCNNNGGCAAGCCGCCUUAAGCCUACUUAGAUGGAAGUGACGUACGGGUAUUGGUAC'
        ss1 = '...((((.(((....)))...)))).((...))...((((.(((..((.(((((......)))))..))..)))...))))..'
        ss2 = '....((((((.....))))...))..((...))....((((((.......((((......)))).......))))...))...'
        pt1 = make_pair_table(ss1, base = 0)
        pt2 = make_pair_table(ss2, base = 0)

        ceb = [0, 1, 2, 25, 33, 34, 35, 81, 82]
        assert list(common_exterior_bases(pt1, pt2)) == ceb
        for x in common_exterior_bases(pt1, pt2):
            assert seq == merge_struct(*split_struct(seq, x, None), x, None)
            assert ss1 == merge_struct(*split_struct(ss1, x, None), x, None)
            assert ss2 == merge_struct(*split_struct(ss2, x, None), x, None)

        cbp = [(4, 23), (5, 22), (26, 32), (27, 31), (37, 79), (38, 78), (50, 63), (51, 62), (52, 61), (53, 60)]
        assert list(common_basepairs(pt1, pt2)) == cbp
        for x in common_basepairs(pt1, pt2):
            assert seq == merge_struct(*split_struct(seq, *x), *x)
            assert ss1 == merge_struct(*split_struct(ss1, *x), *x)
            assert ss2 == merge_struct(*split_struct(ss2, *x), *x)

    def test_findpath_split_00(self):
        seq = 'GCCUUAAGCCUACUUAGAUGGAAGUGACGUACGGGUAUU'
        ss1 = '(......((((((((......)))).......))))..)'
        ss2 = '((((.......((((......)))).......)))...)'
        # Set model details.
        path, barrier = findpath_split(seq, ss1, ss2, RNA.md())
        assert path == [('(......((((((((......)))).......))))..)', 400),
                        ('(.......(((((((......)))).......)))...)', 600),
                        ('(.......((.((((......))))........))...)', 860),
                        ('(........(.((((......))))........)....)', 1210),
                        ('(..........((((......)))).............)', 680),
                        ('((.........((((......)))).........)...)', 770),
                        ('(((........((((......))))........))...)', 430),
                        ('((((.......((((......)))).......)))...)', 280)]
        assert barrier == max((en for ss, en in path)) - path[0][1]

    def test_findpath_split_01(self):
        seq = 'AAAGCCGCCUUAAGCCUACUUAGAUGGAAGUGACGUACGGGUAUUGGUACACGAUUUUACAAAGCCGCCUUAAGCCUACUUAGAUGGAAGUGACGUACGGGUAUUGGUACACGAUUUUAC'
        ss1 = '...((((.(((..((.(((((......)))))..))..)))...))))...............((((.(((..((.(((((......)))))..))..)))...))))............'
        ss2 = '...(((((((.......((((......)))).......))))...)))...............(((((((.......((((......)))).......))))...)))............'
       #ss2 = '....((((((.......((((......)))).......))))...)).................((((((.......((((......)))).......))))...)).............'
        vrna_md = RNA.md()
        #print(f'\n{seq}\n{ss1}\n{ss2}')
        path, barrier = findpath_split(seq, ss1, ss2, vrna_md, th = 99)
        assert path == [('...((((.(((..((.(((((......)))))..))..)))...))))...............((((.(((..((.(((((......)))))..))..)))...))))............', -1140),
                        ('...((((.(((..((.(((((......)))))..))..)))...))))...............((((.(((...(.(((((......)))))..)...)))...))))............', -860),
                        ('...((((.(((..((.(((((......)))))..))..)))...))))...............((((.(((.....(((((......)))))......)))...))))............', -970),
                        ('...((((.(((..((.(((((......)))))..))..)))...))))...............((((.((......(((((......))))).......))...))))............', -900),
                        ('...((((.(((..((.(((((......)))))..))..)))...))))...............((((.(.......(((((......)))))........)...))))............', -750),
                        ('...((((.(((..((.(((((......)))))..))..)))...))))...............((((.........(((((......)))))............))))............', -820),
                        ('...((((.(((..((.(((((......)))))..))..)))...))))...............(((((........(((((......)))))........)...))))............', -730),
                        ('...((((.(((..((.(((((......)))))..))..)))...))))...............((((((.......(((((......))))).......))...))))............', -1070),
                        ('...((((.(((..((.(((((......)))))..))..)))...))))...............(((.((.......(((((......))))).......))....)))............', -920),
                        ('...((((.(((..((.(((((......)))))..))..)))...))))...............((((((.......(((((......))))).......)))...)))............', -1180),
                        ('...((((.(((..((.(((((......)))))..))..)))...))))...............(((((((......(((((......)))))......))))...)))............', -1340),
                        ('...((((.(((...(.(((((......)))))..)...)))...))))...............(((((((......(((((......)))))......))))...)))............', -1060), 
                        ('...((((.(((.....(((((......)))))......)))...))))...............(((((((......(((((......)))))......))))...)))............', -1170),
                        ('...((((.((......(((((......))))).......))...))))...............(((((((......(((((......)))))......))))...)))............', -1100),
                        ('...((((.(.......(((((......)))))........)...))))...............(((((((......(((((......)))))......))))...)))............', -950),
                        ('...((((.........(((((......)))))............))))...............(((((((......(((((......)))))......))))...)))............', -1020),
                        ('...(((((........(((((......)))))........)...))))...............(((((((......(((((......)))))......))))...)))............', -930),
                        ('...((((((.......(((((......))))).......))...))))...............(((((((......(((((......)))))......))))...)))............', -1270),
                        ('...(((.((.......(((((......))))).......))....)))...............(((((((......(((((......)))))......))))...)))............', -1120),
                        ('...((((((.......(((((......))))).......)))...)))...............(((((((......(((((......)))))......))))...)))............', -1380),
                        ('...(((((((......(((((......)))))......))))...)))...............(((((((......(((((......)))))......))))...)))............', -1540),
                        ('...(((((((.......((((......)))).......))))...)))...............(((((((......(((((......)))))......))))...)))............', -1420),
                        ('...(((((((.......((((......)))).......))))...)))...............(((((((.......((((......)))).......))))...)))............', -1300)]
        assert barrier == max((en for ss, en in path)) - path[0][1]
        #for (ss, en) in path:
        #    print(f'{ss} {en:>5d}')
        path, barrier = findpath_split(seq, ss1, ss2, vrna_md, th = 5)
        assert barrier == 410
        #for (ss, en) in path:
        #    print(f'{ss} {en:>5d}')
        path, barrier = findpath_split(seq, ss1, ss2, vrna_md, th = 1)
        assert barrier == 410
        #for (ss, en) in path:
        #    print(f'{ss} {en:>5d}')

    def test_findpath_split_02(self):
        seq = "UGGGAAUAGUCUCUUCCGAGUCUCGCGGGCGACGGGCGAUCUUCGAAAGUGGAAUCCG"
        ss1 = "..((....(((........(((.....)))....)))..(((........)))..))." 
        ss2 = ".((((....))))..(((.(.((...)).)..)))......(((.......)))...."
        #print(f'\n{seq}\n{ss1}\n{ss2}')
        path, barrier = findpath_split(seq, ss1, ss2, RNA.md(), th = 1)
        assert barrier == 200 # may change with a new findpath version?
        #for (ss, en) in path:
        #    print(f'{ss} {en:>5d}')
        #print(barrier)

@unittest.skipIf(SKIP, "skipping tests")
class FloodingTests(unittest.TestCase):
    def test_local_flooding(self):
        seq = "AAAGCCGCCUUAAGCCUACUUAGAUGGAAGUGACGUACGGGUAUUGGUACACGAUUUUAC"
        [ss, en] = ['...((........))...........(((((...((((........))))...)))))..', -9.30]
        minh = 1

        # Set model details.
        vrna_md = RNA.md()
        vrna_md.temperature = 25
        fc = RNA.fold_compound(seq, vrna_md)

        macro, fstep = local_flooding(fc, ss, basinh = minh, rates = False)
        for m in macro:
            em = round(fc.eval_structure(m), 2)
            assert em <= en + minh
        for m in fstep:
            em = round(fc.eval_structure(m), 2)
            assert em > en + minh

    def test_path_flooding_barriers(self):
        seq = "AAAGCCGCCUUAAGCCUACUUAGAUGGAAGUGACGUACGGGUAUUGGUACACGAUUUUAC"
        path = [('......((.....)).(((((......)))))..((((........))))..........',  -956), # L0013
                ('.......(.....)..(((((......)))))..((((........))))..........',  -587), # S
                ('................(((((......)))))..((((........))))..........',  -897), # I
                ('....(........)..(((((......)))))..((((........))))..........',  -631), # S
                ('...((........)).(((((......)))))..((((........))))..........', -1000), # L0010
                ('...((........))..((((......))))...((((........))))..........',  -890), # I
                ('...((........))...(((......)))....((((........))))..........',  -729), # I
                ('...((........))...((........))....((((........))))..........',  -560), # I
                ('...((........))...(..........)....((((........))))..........',  -288), # S
                ('...((........))...................((((........))))..........',  -681), # I # local minimum
                ('...((........))...............(...((((........))))...)......',  -332), # S
                ('...((........))..............((...((((........))))...)).....',  -517), # I
                ('...((........)).............(((...((((........))))...)))....',  -587), # I
                ('...((........))............((((...((((........))))...))))...',  -699), # I
                ('...((........))...........(((((...((((........))))...)))))..',  -930), # L0017
                ('....(........)............(((((...((((........))))...)))))..',  -561), # S
                ('..........................(((((...((((........))))...)))))..',  -827), # I
                ('.............(....).......(((((...((((........))))...)))))..',  -522), # S
                ('............((....))......(((((...((((........))))...)))))..',  -667), # I
                ('...........(((....))).....(((((...((((........))))...)))))..',  -797), # I
                ('..........((((....))))....(((((...((((........))))...)))))..',  -938), # I
                ('.........(((((....)))))...(((((...((((........))))...)))))..', -1008), # I
                ('.....(...(((((....)))))..)(((((...((((........))))...)))))..',  -820), # S
                ('.....((..(((((....))))).))(((((...((((........))))...)))))..',  -890), # I
                ('.....((...((((....))))..))(((((...((((........))))...)))))..',  -820), # S
                ('.....((.(.((((....))))).))(((((...((((........))))...)))))..',  -969), # I
                ('.....((.(.((((....))))).)).((((...((((........))))...))))...',  -738), # S
                ('....(((.(.((((....))))).)))((((...((((........))))...))))...', -1094)] # L0001

        ssmap = path_flooding(path, minh = 300)

        L0013 = '......((.....)).(((((......)))))..((((........))))..........'
        L0010 = '...((........)).(((((......)))))..((((........))))..........'
        L0017 = '...((........))...........(((((...((((........))))...)))))..'
        L0001 = '....(((.(.((((....))))).)))((((...((((........))))...))))...'
        Lhigh = '...((........))...................((((........))))..........'
        saddles = [1, 8, 10, 17]

        mins = set([L0013, L0010, L0017, L0001, Lhigh])
        seen = set()
        for si in sorted(ssmap):
            lm = ssmap[si]
            if isinstance(lm, list):
                assert si in saddles
                assert len(lm) == 2
                lm1, lm2 = sorted(lm)
                assert path[lm1][0] in mins
                assert path[lm2][0] in mins
            else:
                assert path[lm][0] in mins
                seen.add(path[lm][0])
        assert seen == mins

        ssmap = path_flooding(path, minh = 300, maxlm = -956)
        mins = set([L0013, L0010, L0001])
        seen = set()
        for si in sorted(ssmap):
            lm = ssmap[si]
            if isinstance(lm, list):
                assert si in saddles
                assert len(lm) == 2
                lm1, lm2 = sorted(lm)
            else:
                assert path[lm][0] in mins
                seen.add(path[lm][0])
        assert seen == mins

    def test_path_flooding_random(self):
        seq = "UCUACUAUUCCGGCUUGACAUAAAUAUCGAGUGCUCGACCGCUAUUAUGGUACUUUCCAGCGUUUUGAUUGGUGGAUAAUAUCCCCCAAAAACGCGAGUC"
        path = [('............(((((..........)))))((((..((........)).........((((((...((((.((((...)))).)))))))))))))).', -1850), # lmin
                ('............(((((..........))))).(((..((........)).........((((((...((((.((((...)))).)))))))))))))..', -1710),
                ('............(((((..........)))))..((..((........)).........((((((...((((.((((...)))).))))))))))))...', -1440),
                ('............(((((..........)))))...(..((........)).........((((((...((((.((((...)))).)))))))))))....', -1300), # saddle
                ('............(((((..........)))))......((........)).........((((((...((((.((((...)))).)))))))))).....', -1660), # lmin
                ('............(((((..........))))).......(........)..........((((((...((((.((((...)))).)))))))))).....', -1370),
                ('............(((((..........)))))...........................((((((...((((.((((...)))).)))))))))).....', -1620),
                ('...........((((((..........))))).......)...................((((((...((((.((((...)))).)))))))))).....', -1230),
                ('..........(((((((..........))))).......))..................((((((...((((.((((...)))).)))))))))).....', -1390),
                ('..........((.((((..........))))........))..................((((((...((((.((((...)))).)))))))))).....', -1110), # saddle
                ('..........(((((((..........)))).......)))..................((((((...((((.((((...)))).)))))))))).....', -1520), # lmin
                ('....(.....(((((((..........)))).......)))........).........((((((...((((.((((...)))).)))))))))).....', -1100), # saddle
                ('....((....(((((((..........)))).......))).......)).........((((((...((((.((((...)))).)))))))))).....', -1260),
                ('....(((...(((((((..........)))).......)))......))).........((((((...((((.((((...)))).)))))))))).....', -1380),
                ('....((((..(((((((..........)))).......))).....)))).........((((((...((((.((((...)))).)))))))))).....', -1580),
                ('...(((((..(((((((..........)))).......))).....)))))........((((((...((((.((((...)))).)))))))))).....', -1720), # lmin
                ('...(((((..((((((............))).......))).....)))))........((((((...((((.((((...)))).)))))))))).....', -1440),
                ('...(((((..(((((..............)).......))).....)))))........((((((...((((.((((...)))).)))))))))).....', -1280),
                ('...(((((..((((................).......))).....)))))........((((((...((((.((((...)))).)))))))))).....', -1140), # saddle
                ('...(((((..(((.........................))).....)))))........((((((...((((.((((...)))).)))))))))).....', -1560),
                ('...(((((..(((...(..................)..))).....)))))........((((((...((((.((((...)))).)))))))))).....', -1380),
                ('...(((((..(((..((..................)).))).....)))))........((((((...((((.((((...)))).)))))))))).....', -1480),
                ('...(((((..(((.(((..................)))))).....)))))........((((((...((((.((((...)))).)))))))))).....', -1750),
                ('...(((((..(((.((((................))))))).....)))))........((((((...((((.((((...)))).)))))))))).....', -1870),
                ('...(((((..(((.(((((.............).))))))).....)))))........((((((...((((.((((...)))).)))))))))).....', -1860),
                ('...(((((..(((.((((((...........)).))))))).....)))))........((((((...((((.((((...)))).)))))))))).....', -1950),
                ('...(((((..(((.(((((((.........))).))))))).....)))))........((((((...((((.((((...)))).)))))))))).....', -2150),
                ('..((((((..(((.(((((((.........))).))))))).....)))))).......((((((...((((.((((...)))).)))))))))).....', -2270), # lmin
                ('..((((((..(((.(((((((.........))).))))))).....)))))).....(.((((((...((((.((((...)))).)))))))))))....', -2140),
                ('..((((((..(((.(((((((.........))).))))))).....)))))).....(..(((((...((((.((((...)))).))))))))).)....', -1710)]

        saddles = ['............(((((..........)))))...(..((........)).........((((((...((((.((((...)))).)))))))))))....', 
                   '..........((.((((..........))))........))..................((((((...((((.((((...)))).)))))))))).....',
                   '....(.....(((((((..........)))).......)))........).........((((((...((((.((((...)))).)))))))))).....',
                   '...(((((..((((................).......))).....)))))........((((((...((((.((((...)))).)))))))))).....']

        lmins = ['............(((((..........)))))((((..((........)).........((((((...((((.((((...)))).)))))))))))))).', 
                 '............(((((..........)))))......((........)).........((((((...((((.((((...)))).)))))))))).....',
                 '..........(((((((..........)))).......)))..................((((((...((((.((((...)))).)))))))))).....',
                 '...(((((..(((((((..........)))).......))).....)))))........((((((...((((.((((...)))).)))))))))).....',
                 '..((((((..(((.(((((((.........))).))))))).....)))))).......((((((...((((.((((...)))).)))))))))).....']

        ssmap = path_flooding(path, minh = 300)
        for si in sorted(ssmap):
            lm = ssmap[si]
            if isinstance(lm, list):
                assert len(lm) == 2
                lm1, lm2 = sorted(lm)
                #print(path[si], 'saddle')
                assert path[si][0] in saddles
            elif si == ssmap[si]:
                assert path[si][0] in lmins
                #print(path[si], 'lmin')
            else:
                assert path[si][0] not in lmins
                assert path[si][0] not in saddles
                #print(path[si])
 
        #print() # NOTE: A quick check if edge_flooding works.
        #[s1, e1] = path[0]
        #[s2, e2] = path[-1]
        #fp = init_findpath_max(seq)
        #for (ss1, en1, ssB, enB, ss2, en2) in edge_flooding(fp, s1, s2, e1, e2, minh = 300):
        #    print(ss1, en1, ssB, enB, ss2, en2)

@unittest.skipIf(SKIP, "skipping tests")
class NeighborhoodTests(unittest.TestCase):
    def test_guiding_edge_search_btree(self):
        btree = """
              AGACGACAAGGUUGAAUCGCACCCACAGUCUAUGAGUCGGUGACAACAUU
            1 ..........((((.((((.((.((.......)).))))))..))))...  -6.70    0  13.00
            2 ..........((((.((((.((...((.....)).))))))..))))...  -6.10    1   2.10
            3 ..........((((.....((((.((.........)).)))).))))...  -5.90    1   6.30
            4 ((((.....(((........)))....))))....(((...)))......  -5.70    1   8.50
            5 ...((((...)))).....((((.((.........)).))))........  -5.60    3   4.80
            6 .(((......)))......((((.((.........)).))))........  -5.50    5   4.30
            7 ..........((((..((((.....((.....)).....))))))))...  -5.50    3   5.30
            8 ((((.....(((........)))....))))...................  -5.00    4   3.40
            9 ((((.....((.((.....))))....))))....(((...)))......  -5.00    4   2.80
           10 ((((.....((.((.....)).))...))))....(((...)))......  -4.90    4   3.50
        """
        lmins = parse_barriers(btree, is_file = False, return_tuple = True)
        sss = [x.structure for x in lmins[1:]]

        edges = guiding_edge_search(sss)
        #sti = {x.structure: x.id for x in lmins[1:]}
        #for (x, y) in sorted(edges, key=lambda x: (sti[x[0]], sti[x[1]])):
        #    if sti[x] < sti[y]:
        #        print(sti[x], sti[y])

        assert int(len(edges)/2) == 11

    def test_guiding_edge_search_randseq(self):
        seq = "AGACGACAAGGUUGAAUCGCA"
        sss = """(.((......)))........
                 .((((((...))))..))...
                 .(((......)))........
                 .((...((....))..))...
                 .(.(((((....))..)))).
                 .(.((((...))))..)....
                 .(.(((..........)))).
                 .(.((............))).
                 ...(((((....))..)))..
                 ...((((...)))).......
                 ...((((......)..)))..
                 ...(((..........)))..
                 ...((............))..
                 ....................."""
        sss = sorted(set(sss.split()))

        edges = guiding_edge_search(sss)
        #sti = {s: e for e, s in enumerate(sss)}
        #for (x, y) in sorted(edges, key=lambda x: (sti[x[0]], sti[x[1]])):
        #    if sti[x] < sti[y]:
        #        print(sti[x], sti[y])

        assert int(len(edges)/2) == 18

    def test_edge_flooding(self):
        btree = """
              AGACGACAAGGUUGAAUCGCACCCACAGUCUAUGAGUCGGUGACAACAUU
            1 ..........((((.((((.((.((.......)).))))))..))))...  -6.70    0  13.00
            2 ..........((((.((((.((...((.....)).))))))..))))...  -6.10    1   2.10
            3 ..........((((.....((((.((.........)).)))).))))...  -5.90    1   6.30
            4 ((((.....(((........)))....))))....(((...)))......  -5.70    1   8.50
            5 ...((((...)))).....((((.((.........)).))))........  -5.60    3   4.80
            6 .(((......)))......((((.((.........)).))))........  -5.50    5   4.30
            7 ..........((((..((((.....((.....)).....))))))))...  -5.50    3   5.30
            8 ((((.....(((........)))....))))...................  -5.00    4   3.40
            9 ((((.....((.((.....))))....))))....(((...)))......  -5.00    4   2.80
           10 ((((.....((.((.....)).))...))))....(((...)))......  -4.90    4   3.50
        """
        lmins = parse_barriers(btree, is_file = False, return_tuple = True)
        seq, md = lmins[0], RNA.md()
        sss = [x.structure for x in lmins[1:]]
        sti = {x.structure: x.id for x in lmins[1:]}

        s1 = lmins[1].structure
        s2 = lmins[4].structure
        e1 = int(round(lmins[1].energy*100))
        e2 = int(round(lmins[4].energy*100))

        fp = init_findpath_max(seq)
        #for (ss1, en1, ssB, enB, ss2, en2) in edge_flooding(fp, s1, s2, e1, e2, minh = None):
        #    print(ss1, en1, ssB, enB, ss2, en2)
        assert len(list(edge_flooding((seq, md), s1, s2, e1, e2, minh = None))) == 1

        #for (ss1, en1, ssB, enB, ss2, en2) in edge_flooding(fp, s1, s2, e1, e2, minh = 0):
        #    print(ss1, en1, ssB, enB, ss2, en2)
        #fp = init_findpath_max(seq) # TODO remove
        assert len(list(edge_flooding(fp, s1, s2, e1, e2, minh = 0))) == 1 # Used to be 6

        #for (ss1, en1, ssB, enB, ss2, en2) in edge_flooding(seq, md, s1, s2, e1, e2, minh = 300):
        #    print(ss1, en1, ssB, enB, ss2, en2)
        #fp = init_findpath_max(seq) # TODO remove
        assert len(list(edge_flooding(fp, s1, s2, e1, e2, minh = 300))) == 1 # Used to be 3

    def test_neighborhood_flooding(self):
        btree = """
              AGACGACAAGGUUGAAUCGCACCCACAGUCUAUGAGUCGGUGACAACAUU
            1 ..........((((.((((.((.((.......)).))))))..))))...  -6.70    0  13.00
            2 ..........((((.((((.((...((.....)).))))))..))))...  -6.10    1   2.10
            3 ..........((((.....((((.((.........)).)))).))))...  -5.90    1   6.30
            4 ((((.....(((........)))....))))....(((...)))......  -5.70    1   8.50
            5 ...((((...)))).....((((.((.........)).))))........  -5.60    3   4.80
            6 .(((......)))......((((.((.........)).))))........  -5.50    5   4.30
            7 ..........((((..((((.....((.....)).....))))))))...  -5.50    3   5.30
            8 ((((.....(((........)))....))))...................  -5.00    4   3.40
            9 ((((.....((.((.....))))....))))....(((...)))......  -5.00    4   2.80
           10 ((((.....((.((.....)).))...))))....(((...)))......  -4.90    4   3.50
        """
        lmins = parse_barriers(btree, is_file = False, return_tuple = True)
        seq, md = lmins[0], RNA.md()
        ndata = {x.structure: {'energy': int(round(x.energy*100)), 'identity': x.id} for x in lmins[1:]}
        gnodes, gedges = get_guide_graph(seq, md, ndata.keys())
        assert len(gnodes) == 0 # no new guide nodes
        assert len(gedges) == 36

        fp = init_findpath_max(seq)
        ndata, tedges, new_gedges = neighborhood_flooding(fp, ndata, gedges, minh = 200)

        #print()
        #print('a', len(ndata))
        #print('a', len(tedges))
        #print('a', len(new_gedges))
        for ge in new_gedges:
            assert ge not in gedges
            #print(ge)

        # #print()
        # #for te in tedges.items():
        # #    print(te)

        while new_gedges:
            ndata, tedges, new_gedges = neighborhood_flooding(fp, ndata, new_gedges, tedges = tedges, minh = 200)
            #print()
            #print(len(ndata))
            #print(len(tedges))
            #print(len(new_gedges))
            for ge in new_gedges:
                assert ge not in gedges
                #print(ge)

    def test_neighborhood_cycling(self):
        btree = """
              AGACGACAAGGUUGAAUCGCACCCACAGUCUAUGAGUCGGUGACAACAUU
            1 ..........((((.((((.((.((.......)).))))))..))))...  -6.70    0  13.00
            2 ..........((((.((((.((...((.....)).))))))..))))...  -6.10    1   2.10
            3 ..........((((.....((((.((.........)).)))).))))...  -5.90    1   6.30
            4 ((((.....(((........)))....))))....(((...)))......  -5.70    1   8.50
            5 ...((((...)))).....((((.((.........)).))))........  -5.60    3   4.80
            6 .(((......)))......((((.((.........)).))))........  -5.50    5   4.30
            7 ..........((((..((((.....((.....)).....))))))))...  -5.50    3   5.30
            8 ((((.....(((........)))....))))...................  -5.00    4   3.40
            9 ((((.....((.((.....))))....))))....(((...)))......  -5.00    4   2.80
           10 ((((.....((.((.....)).))...))))....(((...)))......  -4.90    4   3.50
        """
        lmins = parse_barriers(btree, is_file = False, return_tuple = True)
        seq, md = lmins[0], RNA.md()
        sss = [x.structure for x in lmins[1:]]

        edges = guiding_edge_search(sss)
        assert len(edges) == 22
        edata = {e: dict() for e in edges}
        ndata = {x.structure: {'energy': int(round(x.energy*100)), 'identity': x.id} for x in lmins[1:]}

        c = nx_cycle_basis(ndata, edata)
        assert len(c) == 2
        fc_empty = forbid_all_basepairs(seq, RNA.fold_compound(seq, md))
        lmins = guiding_node_search(seq, md, ndata, edges, fc_empty)
        del fc_empty
        assert lmins == set()

    def dont_test_neighborhood_flooding_maxh(self):
        btree = """
              AGACGACAAGGUUGAAUCGCACCCACAGUCUAUGAGUCGGUGACAACAUU
            1 ..........((((.((((.((.((.......)).))))))..))))...  -6.70    0  13.00
            2 ..........((((.((((.((...((.....)).))))))..))))...  -6.10    1   2.10
            3 ..........((((.....((((.((.........)).)))).))))...  -5.90    1   6.30
            4 ((((.....(((........)))....))))....(((...)))......  -5.70    1   8.50
            5 ...((((...)))).....((((.((.........)).))))........  -5.60    3   4.80
            6 .(((......)))......((((.((.........)).))))........  -5.50    5   4.30
            7 ..........((((..((((.....((.....)).....))))))))...  -5.50    3   5.30
            8 ((((.....(((........)))....))))...................  -5.00    4   3.40
            9 ((((.....((.((.....))))....))))....(((...)))......  -5.00    4   2.80
           10 ((((.....((.((.....)).))...))))....(((...)))......  -4.90    4   3.50
        """
        lmins = parse_barriers(btree, is_file = False, return_tuple = True)
        seq, md = lmins[0], RNA.md()
        sss = [x.structure for x in lmins[1:]]

        edges = guiding_edge_search(sss)
        assert len(edges) == 22
        edata = {e: dict() for e in edges}
        ndata = {x.structure: {'energy': int(round(x.energy*100)), 'identity': x.id} for x in lmins[1:]}

        edges, edata, ndata = neighborhood_flooding(seq, md, edges, ndata, minh = 200, maxh = 1000, edata = edata)
        assert len(edges) == 22
        edges, edata, ndata = neighborhood_flooding(seq, md, edges, ndata, minh = 200, maxh = 1000, edata = edata)
        assert len(edges) == 22
        edges, edata, ndata = neighborhood_flooding(seq, md, edges, ndata, minh = 200, maxh = 1000)
        assert len(ndata) == 10
        assert len(edges) == 22
        assert len(edata) == 22

        for k in list(ndata): ndata[k]['hiddennodes'] = set()
        cg_ndata, cg_edata = neighborhood_coarse_graining(ndata, edata, minh = 300)
        #print()
        #for n in sorted(ndata, key = lambda x: ndata[x]['energy']):
        #    print(n, ndata[n]['energy'])
        #print()
        #for n in sorted(cg_ndata, key = lambda x: cg_ndata[x]['energy']):
        #    print(n, cg_ndata[n]['energy'], len(cg_ndata[n]['hiddennodes']))
        hiddennodes = set()
        for n in cg_ndata:
            if cg_ndata[n]['hiddennodes']:
                hiddennodes |= cg_ndata[n]['hiddennodes']
        assert len(cg_ndata) == 8
        assert len(cg_edata) == 18
        assert len(cg_ndata) + len(hiddennodes) == 10

    def test_guide_graph_construction(self):
        btree = """
              AGACGACAAGGUUGAAUCGCACCCACAGUCUAUGAGUCGGUGACAACAUU
            #1 ..........((((.((((.((.((.......)).))))))..))))...  -6.70    0  13.00
            2 ..........((((.((((.((...((.....)).))))))..))))...  -6.10    1   2.10
            3 ..........((((.....((((.((.........)).)))).))))...  -5.90    1   6.30
            #4 ((((.....(((........)))....))))....(((...)))......  -5.70    1   8.50
            5 ...((((...)))).....((((.((.........)).))))........  -5.60    3   4.80
            6 .(((......)))......((((.((.........)).))))........  -5.50    5   4.30
            #7 ..........((((..((((.....((.....)).....))))))))...  -5.50    3   5.30
            8 ((((.....(((........)))....))))...................  -5.00    4   3.40
            #9 ((((.....((.((.....))))....))))....(((...)))......  -5.00    4   2.80
           #10 ((((.....((.((.....)).))...))))....(((...)))......  -4.90    4   3.50
        """
        lmins = parse_barriers(btree, is_file = False, return_tuple = True)
        seq, md = lmins[0], RNA.md()
        ndata = {x.structure: {'energy': int(round(x.energy*100)), 'identity': x.id} for x in lmins[1:]}

        #print()
        nodes, edges = get_guide_graph(seq, md, ndata.keys())
        assert all(n not in ndata for n in nodes)

        #ID = 20
        #for (ss, en) in nodes:
        #    ndata[ss] = {'energy': en, 'identity': ID}
        #    ID += 1

        #for n in ndata.items():
        #    print(n)

        #for e, (x, y) in enumerate(sorted(edges), 1):
        #    print(e, ndata[x]['identity'], ndata[y]['identity'])

    def test_minitrafo_randseq(self):
        # A random set of sequences returned by randseq -l 100 | RNAsubopt --stochBT_en=50 | sort -u
        btree = """ 
           CAAAGGCGACUCUCCUUAGACUCUAUAAAUAGUAAAUAGCUCCUAGGGACAAGGCUUACGUCCGCGUUAUUCACAUAAGUCGUCGCUUCAGUUGUGCGAC
        01 ............((((((((..((((.........)))).)).)))))).............................(((((.((.......))))))) -10.40 0 1
        02 .....((((((.(((((((...((.............))...)))))))...(((....)))...((.....))...))))))................. -10.80 0 1
        03 ....((((((..((((((((..((((.........)))).)).))))))...((.(.(((....))).).))......))))))(((......).))... -11.20 0 1
        04 ....(((((((.(((((((...((((.........))))...)))))))..(.((........)).)..........)))))))..(.(.((...)))). -11.60 0 1
        05 .....(((((..(((((((...(((((.....)..))))...)))))))...((((((.((..(.....)..)).))))))))))).............. -13.80 0 1
        06 ...(((((((..((((((....(((...........)))....))))))...((((((.((...........)).)))))))))))))((....)).... -14.20 0 1
        07 ...(.(((.....((((((...((((.........))))...))))))....(((....)))))).)...............((((.........)))). -14.60 0 1
        08 ....((((((...((((((...((((.........))))...))))))....((((((.((...........)).))))))))))))..(....)..... -15.00 0 1
        09 ..((.(((.(..(((((((...((((.........))))...)))))))...)((....)).))).)).............(((((.........))))) -15.10 0 1
        10 ...((....))..((((((...((((.........))))...))))))....((((((.................))))))(((((.........))))) -15.80 0 1
        11 ....((((((..(((((((...((((.........))))...)))))))....((........))((.....)).......))))))............. -16.00 0 1
        12 ....((((((..(((((((...((((.........))))...)))))))...((((((.(.............).))))))))))))...((......)) -16.10 0 1
        13 ....(((((((.(((((((...((.............))...))))))).((.((........)).)).........)))))))((.........))... -16.20 0 1
        14 ..........(.(((((((...((((.........))))...))))))).).((((((.(.............).))))))(((((.........))))) -16.20 0 1
        15 ...((.(.....(((((((...((((.........))))...)))))))...).))......................((((.(((.......))))))) -16.60 0 1
        16 ...(((((((...((((((...((((..(...)..))))...))))))....((((((.((...........)).)))))))))))))............ -17.00 0 1
        17 ....((((((...((((((...((((.........))))...))))))....((((((.((...........)).))))))))))))((.((...)))). -17.00 0 1
        18 ((((((((((..(((((((...((((........).)))...)))))))...((((((.((...........)).)))))))))))))...)))...... -17.20 0 1
        19 ...(((((((..(((((((...((((.........))))...)))))))...((((((.((....(.....))).)))))))))))))((....)).... -17.30 0 1
        20 ...(((((((...(((((((..((((.........)))).).))))))....((((((.((...........)).)))))))))))))............ -17.40 0 1
        21 ((((((((((..(((((((...((((.........))))...)))))))...((((((.((..(......).)).)))))))))))))...)))...... -17.70 0 1
        22 ....((((((..((((((((..((((.........)))).).)))))))...((((((.((...........)).))))))))))))............. -17.90 0 1
        23 .....(((((...((((((...((((.........))))...))))))....((((((.((...........)).))))))))))).............. -17.90 0 1
        24 (..(((((((..(((((((...(((...........)))...)))))))...((((((.((...........)).)))))))))))))..)......... -18.10 0 1
        25 ....(((((((.(((((((...((((.........))))...)))))))..(.((........)).)..........)))))))((.........))... -18.20 0 1
        26 (..(((((((..(((((((...((((.........))))...)))))))...((((((((....))).........))))))))))))..)......... -18.30 0 1
        27 ...(((((((..((((((((..((((.........)))).).)))))))...((((((.((...........)).)))))))))))))............ -18.50 0 1
        28 ((((((((((..(((((((...((((.........))))...)))))))...((((((.(.............).)))))))))))))...)))...... -18.70 0 1
        29 ...((((.....(((((((...((((.........))))...)))))))....))))........................(((((.........))))) -18.70 0 1
        30 ....((((((..(((((((...((((.........))))...)))))))...((((((.((...........)).))))))))))))...(((....))) -18.70 0 1
        31 ...(((((((..(((((((...((((.........))))...)))))))...((((((.((...........)).)))))))))))))..((...))... -18.90 0 1
        32 ....((((((..(((((((...((((.........))))...)))))))...((((((.((...........)).))))))))))))((........)). -18.90 0 1
        33 .....((((((.(((((((...((((.........))))...))))))).((.((........)).)).........))))))(((.........))).. -18.90 0 1
        34 ....((((((...((((((...((((.........))))...))))))....((((((.((...........)).))))))))))))............. -19.20 0 1
        35 ..((.(((....(((((((...((((.........))))...)))))))...(((....)))))).)).............(((((.........))))) -19.30 0 1
        36 ...(((((((...((((((...((((.........))))...))))))....((((((.((...........)).)))))))))))))............ -19.80 0 1
        37 ....((((((..(((((((...((((.........))))...)))))))...((((((.((...........)).))))))))))))............. -20.30 0 1
        38 ...(((((((..(((((((...((((.........))))...)))))))...((((((.((...........)).)))))))))))))............ -20.90 0 1
        39 ....(((((((.(((((((...((((.........))))...)))))))....((........))............)))))))................ -17.60 0 1
        """
        lmins = parse_barriers(btree, is_file = False, return_tuple = True)
        seq, md = lmins[0], RNA.md()

        #print()
        ndata = {x.structure: {'energy': int(round(x.energy*100)), 'identity': x.id} for x in lmins[1:]}


        #print(f'Finding guide neighborhood for {len(ndata)=}.')
        gnodes, gedges = get_guide_graph(seq, md, ndata.keys())
        #print(f' - Found {len(gedges)} guide edges and {len(gnodes)} new guide nodes.')
        for (ss, en) in gnodes:
            ndata[ss] = {'energy': en}

        #print(f'Total of {len(ndata)} lmins.')
        tedges = dict() 
        fp = init_findpath_max(seq)
        while gedges:
            #print(len(gedges))
            ndata, tedges, gedges = neighborhood_flooding(fp, ndata, gedges, tedges = tedges, minh = 200)

        # Those results are not constant ... why?
        #assert len(gedges) == 0
        #assert len(ndata) == 98
        #assert len(tedges) == 364

        #print(len(ndata), len([(x,y) for (x, y) in tedges if tedges[(x,y)]['saddle_energy'] is not None]))
        for k in list(ndata): ndata[k]['hiddennodes'] = set()
        cg_ndata, cg_edata = neighborhood_coarse_graining(ndata, tedges, minh = 200)

        #print()
        #for n in sorted(ndata, key = lambda x: ndata[x]['energy']):
        #    print(n, ndata[n]['energy'])
        #print()
        #for n in sorted(cg_ndata, key = lambda x: cg_ndata[x]['energy']):
        #    print(n, cg_ndata[n]['energy'], len(cg_ndata[n]['hiddennodes']))

        hiddennodes = set()
        for n in cg_ndata:
            if cg_ndata[n]['hiddennodes']:
                hiddennodes |= cg_ndata[n]['hiddennodes']
        assert len(cg_ndata) + len(hiddennodes) == len(ndata)

if __name__ == '__main__':
    unittest.main()
